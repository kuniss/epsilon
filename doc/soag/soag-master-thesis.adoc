//  Page 1

= Ein Evaluatorgenerator für zwei heuristische TeilklassenSequentiell Orientierbarer Erweiterter Affixgrammatiken

Master Thesis

March 1998

Denis Kuniß

Technische Universität Berlin

Fachbereich Informatik

Institut für Angewandte Informatik

FG Programmiersprachen und Compiler

// -------------------------------------------------------------------------------
//  Pages 2-3 Content Directory

// -------------------------------------------------------------------------------
// Page 4

== Foreword
The present diploma thesis is the provisional conclusion of an intensive occupation of several years with theory and practice of compiler generation. The discussion of this topic was the main focus of my studies and was supported by the FG Programming Languages and Compilers of the Department of Computer Science at the TU Berlin under the direction of Prof. Dr. Bleicke Eggers. InSönke Kannapinn and Mario Kröplin in particular, who have supported my fascination for this subfield of for this subfield of computer science through excellent lectures and didactically outstanding seminars and tutorials. I owe a large part of my engineering-technical knowledge to them.

I would like to thank Prof. Eggers for his efforts to present a holistic view of things in his lectures, which is not limited to the field of computer science, and for providing food for thought about the responsibilities of engineers and scientists, responsibility of the engineer or scientist for the future. His lectureson the social relevance of computer science, I have rediscovered my inclination for philosophy and and that I have been sensitized for socio-critical considerations.

This paper is intended for readers who are familiar with the problems of compiler generation and formallanguages in general and the ordered attribute grammars [Kastens] and Extended Affix Grammars <<Watt>> in particular. Furthermore, a previous reading of thethesis by Demuth and Weber <<DeWe>> or the research report <<DeWeKrKa>>  is recommended.

I dedicate this work to my wife Julia.
Berlin, March 26, 1998.
Denis Kuniß


// -------------------------------------------------------------------------------
// Page 5

== Introduction

Compilers basically realize complex partial functions: they map elements of a well-defined subset of all buildable strings into other strings; the definition and value domain of a compiler understood as a function are formal languages. The implementation of a compiler results is in principle the result of the comparison of sentences of the source language and the sentences of the target
target language. The number of sentences in a formal language is however potentially infinite, a Compilerof this form would therefore not be recordable. Now the sentences of many languages can be structured in such a way that
a finite structure of all sentences of a language can be derived. These structures, called grammars could now, since they are finite, be used constructively for the comparison in a compiler.

Unfortunately this comparison is not comprehensible in "handwritten" compilers. Thus however
the actual function of a compiler is not transparent. Also the best and most exact manual of a
compiler does not describe its function completely. The only complete description of the
functionality of a compiler is its coding. But who wants to be expected to read the source code of a compiler for verification, especially the actual translation structure of programming styles, inadequacies of the used programming language or optimizations, if the source code is at all available.
Source code at all is available. Desirably a formalism would be, in which structures of the source and target language in a simple, clear form to be contrasted and from which automatically
a compiler can be generated.

The _attribute grammars_ (AGs) introduced by Knuth provide a formalism that can be used not only to describe not only for the description of programming languages, but also as basis for the automatic generation of compilers. This formalism requires as open calculus however the use of a further specification or programming language for the description of the context conditions and the context conditions and the semantics of a language. This complicates the understanding of the compiler and obscures its actual functionality, as in the "handwritten" compiler.

The _extended affix grammars_ (EAGs) introduced by Watt represent a closed calculus and compensate for this disadvantage <<Watt>>. Syntax and semantics of a programming language are described in a formalism, which omits all non-relevant information - concerning the optimization, the used Implementation language used and other - concerning - renounces. The comparison of the source and target language is explicit and describes the transformation function to be realized by the compiler to be realized by the compiler unambiguously and in simple form. In 1984 a compiler generator called Eta was developed by Schröer at the Department of Computer Science of the TU Berlin based on the Extended Affix Grammars <<Schröer>>. advantages of this concept for the automatic generation of translators and has been used since then with many has since been used with many extensions also in the context of courses. One of these extensions transfers the principle of ordered attribute grammars (OAGen, [Kastens]) into the world of extended Affix  Grammars and was integrated into the compiler generator Eta by Kutza in 1989 [Kutza]. The OAGen are a polynomial subclass of the multi-visit AGs introduced by Engelfriet [Engelfriet]. For multi-visit AGs a runtime and size efficient evaluator can be given, unfortunately the decision whether a multi-visit AG exists is NP-complete.

OAGs are computed via the polynomial computability of a total order over the attribute of each grammar symbol X, such that in every possible attributed derivation tree the attribute instances of an instance of X can always be evaluated according to this order, are defined. However, there are always practical AGs occur for which such a total order of attributes cannot be computed. Kastens gives different possibilities to be able to order the attributes of an AG after all <<KaHuZi>>, which however leave many problematic AGs unnoticed. Kröplin and Kannapinn have in their work a generalization of one of these ideas <<KröpKann>>. The AGs they specify are _sequentially orientable_ AGs (SOAGs) are a subclass of mult-visit AGs, and the decision,  whether an AG is an SOAG is also NP-complete. The authors present a procedure to identify the AG "responsible" for the NP-completeness "responsible" nondeterminism with an ad hoc determinism, whereby an attribute evaluation order can be computed for all OAGs and many non-OAGs.

The task of the present diploma thesis was to transfer the principle of SOAGs to the Extended grammars and to implement an evaluator generator for the outlined procedure. implemented. The starting point for this is the compiler generator _Epsilon_, which was developed at the TU Berlin under the guidance of Kröplin and Kannapinn in the context of the diploma thesis of Demuth and Weber.

// -------------------------------------------------------------------------------
// Page 6

<<DeWe>>. It replaces the predecessor system Eta, which was "outdated" in its conception and could not be further maintained with the extremely low system _Eta_ and, in particular, provides a parser generator with scanner.

The paper describes the implementation of the principle of SOAGs in the concept of Extended Affix Grammars and closely follows it. In order to underline this concern and to clarify the complexity of the implementation, the source texts are commented.implementation, the source texts are commented and reprinted in the original. Thus the description of abstract algorithms is omitted. This work can describe the underlying theory only rudimentarily in terms of the implementation. in the sense of the implementation, for a comprehensive treatment must be referred to appropriate sources <<KröpKann>>. must be referred to <<KröpKann>>.

The following documentation starts with a general overview of the implementation and the auxiliary modules used. Chapter 3 introduces the terminology of the EAGs and documents the central data structures. data structures. Chapters 4, 5 and 6 present the modules which create the prerequisite for the generation of an evaluator. of an evaluator; this includes the computation of evaluation sequences, visit sequences and optimization information. Chapter 7 undertakes an effort analysis of the presented algorithms, and in the last chapter the actual code generation is treated.

The appendix contains a reduced example with the module generated by the evaluator generator, as well as an analysis of two non-OEAGs that are recognized as SOEAGs by the generator.

// -------------------------------------------------------------------------------
// Page 7

==  General information about the implementation

Based on the existing compiler generator Epsilon the programming was done with the programming language Oberon <<ReiWi>> in the operating system of the same name. In order to have a uniform working and test environment, Oberon was likewise selected as target language of the generation. The compiler generator Epsilon contains the two basic modules _IO_ and _eSets_, which are also used in this system extension. system extension. A description of these two modules can be found in <<DeWe>>. The programming techniques suggested there of the grouping of program objects of a type in a field is further used. Data type extensions are made by creating a parallel field. To
each field `_F_` there is a constant `_firstF_`, which symbolizes the first usable index of the field, and a variable `_NextF_`, which points to the first empty field entry. The fields are expanded by module-local procedures named `Expand`. Undefined references to these fields are represented by the constant `nil`.

=== Lists and Stacks

The `eAList` module implements lists as dynamically expandable fields and implements the following
Interface:Lists and Stacks
The module eAList implements lists as dynamically extendable fields and realizes the following interface:

----
DEFINITION eALists;
    CONST
        firstIndex = 0;
    TYPE
        AList = POINTER TO AListDesc;
        AListDesc = RECORD
            Last: INTEGER;
            Elem: OpenList;
        END;

    PROCEDURE Append (VAR List: AList; Value: INTEGER);
    PROCEDURE Delete (VAR List: AList; Index: INTEGER);
    PROCEDURE IndexOf (VAR List: AList; Value: INTEGER): INTEGER;
    PROCEDURE New (VAR List: AList; Len: INTEGER);
    PROCEDURE Reset (VAR List: AList);
END eALists.
----

The procedures `New` and `Reset` create a new list and empty it respectively. The procedure `Append` adds an element to the the end of the list. The `Delete`  procedure deletes an element from the list by overwriting the position of the element to be deleted with the last element of the list. overwriting the position of the element to be deleted with the last element of the list and shortening the list by one element. element from the list. Thus, the action is of constant effort, but changes the sequence  within the list. The `IndexOf` function returns the list index of an element. The element is determined by linear search.

Furthermore, an `eStacks` module was implemented to describe basement storage. This module is based on the previous module and implements the known basement storage procedures:

// -------------------------------------------------------------------------------
// Page 8

----
DEFINITION eStacks;
    
    IMPORT eALists;

    TYPE
        Stack = POINTER TO RECORD (eALists.AListDesc) END;

    PROCEDURE IsEmpty (S: Stack): BOOLEAN;
    PROCEDURE New (VAR S: Stack; Len: INTEGER);
    PROCEDURE Pop (VAR S: Stack; VAR Val: INTEGER);
    PROCEDURE Push (VAR S: Stack; Val: INTEGER);
    PROCEDURE Reset (VAR S: Stack);
    PROCEDURE Top (VAR S: Stack; VAR Val: INTEGER);

END eStacks.
----

=== Different implementations of sets

The base module `eSets` proved to be unsuitable in effort-critical sections of the implementation. In particular, the elements contained in a set could not be accessed efficiently as a list.  the bit vector representing the set, even for sparse sets, would have had to be traversed completely. would have had to be traversed completely. It is obvious to extend the data structure of the base module by a list of the elements contained in the set. contained in the set. This allows efficient access and increases the memory requirement only slightly for sparse sets. only insignificantly for sparse sets. This approach was realized in the module `eBSets` with the following interface:

----
DEFINITION eBSets;

    IMPORT eALists;

    CONST
        firstIndex = 0;

    TYPE
        BSet = POINTER TO BSetDesc;
        BSetDesc = RECORD
            Max: INTEGER;
            List: eALists.AList;
        END;

    PROCEDURE Delete (VAR S: BSet; Elem: INTEGER);
    PROCEDURE In (S: BSet; Elem: INTEGER): BOOLEAN;
    PROCEDURE Insert (VAR S: BSet; Elem: INTEGER);
    PROCEDURE New (VAR S: BSet; MaxElem: INTEGER);
    PROCEDURE Reset (VAR S: BSet);

END eBSets.
----

The `BSetDesc` data structure contains a bit vector that is not visible in the interface and is declared as follows. declared as follows:
    
----  
    BitVector: eSets.OpenSet;
----

The procedure `New` creates a set of constant size. `Reset` deletes the content of a set, the allocated data structure is preserved and can be reused. The function `In` checks whether an element is contained in the set. set is contained. The list of elements contained in the set S can be effectively accessed by constructs of the type S.List<<eBSets.firstIndex>> to S.List<<S.List.Las>>]. The procedures Insert and Delete add an element to the set and delete it from the set, respectively. The deletion of an element is of linear effort in this implementation, because the list of the contained elements must be searched for it. 

The linear overhead for deleting an element can unnecessarily increase the overhead of an algorithm by a power of by a power. Therefore, quantities have been implemented in the `eASets` module that allow the deletion of a 

// -------------------------------------------------------------------------------
// Page 9

element in constant time and for which the list of elements contained in a set can be retrieved efficiently. can be retrieved. The interface is similar to the previous module:

DEFINITION eASets;
    IMPORT eALists;
        
    CONST
        firstIndex = 0;
    
    TYPE
        ASet = POINTER TO ASetDesc;
        ASetDesc = RECORD
            Max: INTEGER;
            List: eALists.AList;
        END;

    PROCEDURE Delete (VAR S: ASet; Elem: INTEGER);
    PROCEDURE In (S: ASet; Elem: INTEGER): BOOLEAN;
    PROCEDURE Insert (VAR S: ASet; Elem: INTEGER);
    PROCEDURE IsEmpty (VAR S: ASet): BOOLEAN;
    PROCEDURE New (VAR S: ASet; MaxElem: INTEGER);
    PROCEDURE Reset (VAR S: ASet);
    PROCEDURE Test;
END eASets.

The only addition is the `IsEmpty` function, which indicates whether a set is empty. In contrast to `eBSets` the bit vector was omitted completely. The elements are entered into the list `ASet.List` in the order of their insertion into the set. the set into the list `ASet.List`, where `ASet.List.Last` refers to the last element entered. element. The list is implemented as a field and results from the field entries of `ASets.List<<eASets.firstIndex>>` to `ASets.Lis<<ASet.List.Last>>`. If the value i of an element to be inserted into the set is greater than `ASet.List.Last`, then i is appended to the end of the list and a pointer to the end of the list is entered in the field position `ASet.List<<i>>`. If the value i of the element is less than or equal to `ASet.List.Last`, it is inserted at the position ASet.List[i]. is entered. The element that was previously at its position is moved to the end of the list and its pointer is and its pointer is moved accordingly. This procedure divides the field into two halves. In the  first part lists the elements contained in the set. The second part contains for all set elements whose value is greater than `ASet.List.Last`, a value greater than zero on their field position and otherwise the value noelem. When the contents of the set S are changed by the interface procedures the following invariants are preserved in the `ASet.List field`. For all field indices i less-than-equal to the data element `ASet.List.Last`:
----
    ASet.List[i]=i ⇔ i∈S ∧ ASet.List[i]≠i ⇒ ASet.List[i]∈S
----

and for all field indices `i` that are greater than the data element `ASet.List.Last`:

----
    i∈S ⇔ ASet.List[i]≠noelem ∧ i∉S ⇔ ASet.List[i]=noelem
----

From these invariants it is very easy to derive when an element is contained in a set. This makes the bit vector superfluous. The procedures Insert and Delete can be realized with constant effort.

In summary it can be stated that the module `eASets` is particularly well suited for the implementation of densely populated sets, while the module `eBSets` is more suitable for sparsely populated sets, when no time-critical time-critical deletion of elements is required. Both modules can only  constant sets, dynamic extensions during runtime are not possible.

Both set implementations use the `eAList` module. However, this is a complete
encapsulation - you should not apply the interface procedures of the `eAList` module to the list data module `eAList` on the list data structures of the sets, since this can make the data structure inconsistent. The option of dynamic extensibility of lists is not used in the implementations of the sets.

For all generated compilers additionally the independent module `eLIStacks` was implemented, which manages data elements of the type `LONGINT`.

// -------------------------------------------------------------------------------
// Page 10

=== System structure

The SOAG evaluator generator extends the original compiler generator Epsilon by the modules shown in Fig. 3-1. The arrows indicate significant import relationships between the modules. The modules `eALists`, `eStacks`, `eASets`, and `eBSets` are used multiple times to implement Lists, Sets, and Cellar Stores, which can be instantiated in any number. The modules with the "SOAG" prefix describe the actual SOAG evaluator generator. The module `SOAG` contains the central data structures of the generator. In the module `SOAGPartition` the Affixpartition of the analyzed grammar is calculated and thus it is decided whether the generation of an evaluator is possible. In

// doc\soag\images\image-3.1-system-structure.PNG

`SOAGVisitSeq`, the visit sequences for the evaluator are calculated using the `SOAGHash` module, which implements a hash table. Optionally, the `SOAGOptimizer` module provides information to information is provided by the module `SOAGOptimizer`, which allows an optimization of the generated evaluator by storing affix variables in cellar memories and global variables. The module `SOAGGen` generates from the Visit sequences the  The module `SOAGProtocol` serves above all for the logging of central data structure contents during development. central data structure contents during the development.

As in the original compiler generator Epsilon, all modules are prefixed with an "e" to prevent name conflicts with the Oberon system.

// -------------------------------------------------------------------------------
// Page 17

== Definition of terms and internalization

This chapter provides a brief formal definition of EAGs to capture the terminology used in the rest of the paper. terminology used in further work. It is closely based on the definitions of Kutza [Kutza]. Since however EAGen in the compiler generator Epsilon are no longer available in normal form, some extensions and new definitions became necessary. The terms _affix parameter_ and _defining affix_ are newly introduced and the data structure for the internal representation of the EAGen is described.

=== Terminology and definition of EAGs

An Extended Affix Grammar is an 8-tuple
----
    	EAG = (MN, MT, MR, HN, HT, SPEC, HR, S)
----
whose individual components are defined as follows:

-_MN_ is a finite set of _meta-non-terminals_. If _M_ ∈ _MN_, then _M_, _M1_, _M2_, ... as well as _#M_, _#M1_, _#M2_, ... _Affixes_ to _M_.
For any affix _A_ to _M_, _dom(A)_ := _M_ is the range of values of the `affix`. In several other sources the term _variable_ is used synonymously to the term `affix`.

-_MT_ represents the finite set of _meta-terminals_ with MN ∩ _MT_ = ∅.

-_MR_ represents the finite set of _meta-rules_ of the form _M~0~_ = _M~1~_.... _M~n~_ with _n0_ and _M~0~_ ∈ _MN_ and _M~i~_ ∈ _MN_ ∪ _MT_).

The context-free grammar _MG~M~_ := (_MN_, _MT_, _MR_, _M_) is called the meta-grammar spanned by the meta-non-terminal _M_ is called the _meta-grammar_ spanned by the meta-non-terminal _M_. _Affix forms_ to a meta-non-terminal M are sentence forms of MG~M~ in which all occurring meta-nonterminals have been replaced by corresponding affixes.

-_HN- is a finite set of _hyper-nonterminals_.

-_HT_ is a finite set of _hyper-terminals_, with _HN_ ∩ -HN_ = ∅.

-_SPEC_ is a finite set of _specifications_ of the form _H_ _( dir(a~1~) dom(a~1~), ..., dir(a~#a(H)~) dom(a~#a(H)~))_,
therein are:

-_#a(H)_ is the ordinality of _H_

-the tuples _ai_ with _0 < i ≤ #a(H)_ affix positions of H, which are also named in the form ai H ai H. The set A(H) = { a~i~^H^ : 0 < i ≤ #a(H)} is the set of all affix positions of the hypernonterminal _H_.

-_dir(a~i~)_ ∈ {↑,↓} is the direction of the affix position _a~i~_. Affix positions with the direction ↓ are  _inherited_, those with the direction ↑ _synthesized_. _I(H)_ and _S(H)_ denote the sets of inherited and derived affixes of the hyper-nonterminal _H_, respectively.

-_dom(a~i~)_ ∈ _MN_ the range of values of an affix position

The specification of an _EAG_ is not explicitly present in the calculus of the compiler generator Epsilon, but is integrated into the syntactic structure of the hyper-rules for simplification. Formally, however, a separation is is unavoidable and also easier to handle. 

If one inserts affix forms of the corresponding value range into the affix positions of a hyper non-terminal, then a _symbol occurrence_ results which is formally defined as follows: 

If _H( dir(a~1~)_ M~1~, ..., _dir(a~#a(H)~) M~#a(H)~_ is a specification and _f~1~, .., f~#a(H)~_ are affix forms to _M~1~, .., M~#a(H)~_, then _H_, parameterised with affix forms _H(f~1~, .., f~#a(H)~)_, is a _symbol occurrence_. In other sources the term _hypernotion_ is also used.

- _HR_ is a finite set of hyper-rules. A hyper-rule _r_ consists of one left and one right rule side and has the form _X~0~ : X~1~ ... X~n~_ with _~n~≥0_, where _X~0~_ is a symbol occurrence and the _X~i~_ are symbol occurrences or hyper-terminals. The colon separates the left-hand rule side from the right. So that the symbol occurrences can be clearly distinguished outside the rule context, they are additionally they are additionally parameterised with the rule: _X^i^~r~_.

Within the generation of an evaluator, the hyper-terminals of a hyper-rule are abstracted.
The expression _#S(r)_ defines the number of symbol occurrences in the rule _r_.

// -------------------------------------------------------------------------------
// Page  18

In the context of a rule, the parameters ai of a symbol occurrence X(a~1~,..,a~#a(H)~) are called _affix parameters_. In order to be able to distinguish affix parameters unambiguously even without the context of the rule, they are with the rule _r_ and the index of the symbol occurrence _X~i~_: _a~k~^(r,i)^_. The position index _k_ refers either to the position of the affix parameter in the list of affix parameters of the symbol occurrence or, if the index of the symbol occurrence is omitted, to the position in the list of all affix parameters of a rule _r_: _a~k~^(r)^_. The expression _#a(r)_ quantifies the number of all affix parameters used in the rule _r_. The term affix parameter has been redefined in this work. In <<ZiVoKüNa>> there is the affix positions of the specification and the parameterisation of the symbol occurrences are not conceptually affix parameters are defined as affix positions of a rule. This would lead to confusion, especially in the description of the implementation, since affix parameters, as can be seen in thedefinition below, some affix parameters have other properties that cannot be applied to affix positions in any way. are in no way transferable to affix positions. Kutza defines the synonymous term of _affix occurrence_ <<Kutza>>, which I do not consider adequate, but for historical reasons it has found its way into the implementation.  for historical reasons. However, since there is a close relationship between affix parameters and affix positions, the following conceptual relation is defined: An affix parameter a~k~^(r,i)^ of a rule _r corresponds_ to an affix position _a~j~^X^_,  if _X~i~^r^_ =_X_ and _k=j_ holds. In this case _X~i~^r^_ is a symbol occurrence for the symbol _X_ in rule _r_, and the  affix parameter _a~k~^(r,i)^_ is on the _j_-th parameter position of the symbol occurrence _X~i~^r^_.

The set of all affix parameters of a rule r is defined by _AP(r)_ := { a~k~^(r,i)^: 0 _<i≤#S(r)_ and 0<k≤_#a(X~i)~}_. An affix parameter a~k~^(r,i)^ is called defining if with _X=X~i~_ holds: (_i_=0 and _dir(a~k~^X^)_= ↓) or (_i_>0 and _dir(a~k~^X^)_=↑), and applicative if with _X=X~i~_ holds: (_i_=0 and _dir(a~k~^X^)_=↑) or (_i_>0 and _dir(a~k~^X^)_= ↓). _AP~D~(r)_ and _AP~A~(r)_ denote the sets of defining and applying affix parameters, respectively. The content of each applying affix parameter (a^(r,i)^) results from its affix form. The affix form, in turn, consists of affixes that result from defining affix parameters of the rule _r_. Thus, (a^(r,i)^) is defined as a function of a set D(a^(r,i)^) of affix parameters of the same rule. The well-formedness conditions ensure that the _EAG_ is in _Bochmann normal form_, i.e. that there are no applying affix parameters are contained in D(a^(r,i)^) are contained. _D_ is interpreted in the usual way as a relation on affix parameters, i.e. 

_(a^(r,i)^), b^(rj)^)_ ∈ _D_ ⇔ _b^(rj)^)_ ∈ _D(a^(r,i)^)_, 

where the dependencies in the direction of data flow are described by 

_D^-1^_ = { _(b^(rj)^, a^(r,i)^)_: _(a^(r,i)^, b^(rj)^)_ ∈ _D_}.

An affix is a _defining affix_ if it is textually placed in a hyper-rule before all other affixes of the same name in an affix form of a defining affix parameter. affixes in an affix form of a defining affix parameter. A hyper-rule is _left-defining_, if for every affix _V_ in applying affix parameters and for every negated affix _#V_ in defining affix parameters, there exists a defining affix _V_.

-_S_ is an excellent hyper-nonterminal, the starting symbol with specification _S(↑M)_, where _M_ ∈ _MN_. 

_EAGs_ allow the formulation of so-called predicates. Predicates are specified by hyper-nonterminals which can be derived empty or fail. It makes sense to split the _EAG_ into a generative and a predicative part, since predicates contribute nothing to the context-free structure of the source language.

The set of _basic non-terminals GN_ of an _EAG_ is inductively defined as follows:

-_S_ is a basic non-terminal;

-if a hyper-rule contains a hyper-terminal on the right-hand side of the rule, then the hyper-non-terminal on the left-hand side of the rule is a basic non-terminal. on the left-hand side of the rule is a basic non-terminal;

-if a hyper-rule on the right-hand side of the rule contains a basic non-terminal, the hyper-non-terminal on the left-hand side of the rule is a basic non-terminal. on the left-hand side of the rule is a basic non-terminal. 
The set _PN_ of _predicate non-terminals_ contains all hyper-non-terminals which are not basic non-terminals. are.

A hyper-rule is a _predicate rule_ if on its left-hand side there is a symbol occurrence of a predicate non-terminal; all other rules are evaluator rules. The basic grammar (also called _parser grammar_) of an _EAG_ is a context-free grammar consisting of the basic non-terminals, the hyper-terminals and the evaluator rules. hyper-terminals and the evaluator rules, in which the predicate non-terminals and all parameterisations have been parameterisations have been eliminated. The start symbol of the _EAG_ remains as the start symbol.

A parser generated from the basic grammar produces derivation trees of the parser grammar, which, however, no longer contain hyper-terminals. no longer contain hyper-terminals. A derivation tree _t_ is an ordered tree. Each node of _t_ is

// -------------------------------------------------------------------------------
// Page 19

is marked with a basic non-terminal. For each node _k_ of the derivation tree _t_ there exists a rule _r=X~0~^r^_ : _X^r^~1~,...,X^r^~#S(r)~_, so that _k- instance of the symbol occurrence _X~0~^r^_ and its sons are instances of the symbol occurrences _X^r^~1~,...,X^r^~#S(r)~_; _k_ is additionally marked with _r_. Furthermore, each node is assigned the instances of the affixes occurring in the hyper-rule - called _affix variables_ - are assigned to each node. of the defining affix and contain the translation of the evaluation. The root of each derivation tree generated by the parser is an instance of the start symbol _S_ of the _EAG_. 

// -------------------------------------------------------------------------------
// Page

// Example for image
// doc\soag\images\image-3.1-system-structure.PNG

----
Example for code snippet
----

// images sind unter C:\Users\Max Kuniß\git\epsilon\doc\soag\images

// -------------------------------------------------------------------------------
// Page 103 References

[[[bibliography]]]
== References

[[[COMA]]] Wagner, Ripphausen-Lipa, Scheffler: Computerorientierte Mathematik II, Skript zur LV, SS 1991

[[[DeWe]]] Jochen Demuth, Stephan Weber: Eine konzeptionelle Revision des Eta-Compilergenerators und ihre Implementierung, Diplomarbeit TU Berlin, Fachbereich Informatik, Institut für Angewandte Informatik,
Dezember 1996

[[[DeWeKaKr]]] Jochen Demuth, Stephan Weber, Sönke Kannapinn, Mario Kröplin: Echte Compilergenerierung - Effiziente Implementierung einer abgeschlossenen Theorie  aus der Reihe Forschungsberichte des FB Informatik, Bericht 1997/6

[[[Engelfriet]]] J. Engelfriet: Attribute grammars: Attribute evaluation methods In B.Lorho, editor, Methods and Tools for Compiler Construction, pages 103-138, Cambridge University Press 1984

[[[EngFil]]] J. Engelfriet, G.Filé: Simple multi-visit attribute grammars, Journal of Computer and System Sciences, 24(3):283-314, June 1982

[[[EngJong]]] Joost Engelfriet, Willem de Jong: Attribute Storage Optimization by Stacks, Acta Informatica 27, 568-581, 1990

[[[GySiMa]]] Gyimoth, Simon, Makey, An implementation of the HLP. in Acta Informatica 1983, 06/83

[[[IbaKat]]] T.Ibaraki, N.Katoh: On-line computation of transitive closures of graphs, Information Processing Letters, 16:95-97, 1983

[[[Kastens]]] U.Kastens: Ordered Attribute Grammars.
Acta Informatica, 13(3): 229-256, 1980

[[[KaHuZi]]] U.Kastens, B.Hutten, E.Zimmermann: GAG: A Practical Compiler Generator, Volume 141 of Lecture Notes in Computer Science
Springer Verlag 1982

[[[KröpKann]]] Mario Kröplin, Sönke Kannapinn:  Sequentiell orientierbare Attributgrammatiken Vorabdruck, TU Berlin, Fachbereich Informatik, Institut für Angewandte Informatik, 25. Januar 1995

[[[Kutza]]] Karsten Kutza:  Evaluation geordneter EAGen im eta-Compiler-Generator, Bericht 1989/2 TU Berlin, Fachbereich Informatik, 1989

[[[Mehlhorn]]] Kurt Mehlhorn: Graph Algorithms and NP-Completeness
ETACS Series in Computer Science, Springer Verlag

[[[ReiWi]]] Martin Reiser, Niklaus Wirth: Programmieren in Oberon: Das neue Pascal, Bonn-Paris, Addison-Wesley 1994

[[[RepTei]]] T.W.Reps, T.Teitelbaum: The Synthesizer Generator: A System for Constructing Language-Bases Editors Texts and Monographs in Computer Science, Springer-Verlag, 1988

[[[Schröer]]] F.W. Schröer: Eta: Ein Compiler-Generator auf Basis zweistufiger Grammatiken, Bericht 84/2, TU Berlin, Fachbereich Informatik, März 1984, 104

[[[Watt]]] D.A. Watt: Analysis Oriented Two Level Grammars, Ph. D. thesis, Galsgow 1974

[[[ZiVoKüNa]]] B.Zimmermann, K.Voßloh, D.Kürbis, N.Nayeri: Compiler-Generierung II: Spezifikationskalküle und Implementierungskonzepte, Skript einer Lehrveranstaltung an der TU Berlin WS94/95
